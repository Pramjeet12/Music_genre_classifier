{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb305f18-7e6f-4c03-b6b5-9d435ecd72e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b17324e-5117-4a1e-b59f-98846d2019bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b715f295-3787-42e6-8697-159e0177b987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6ef17cf-9693-4176-9f36-8548462ead34",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dataset_path=\"Data/genres_original\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b2b5844-84fc-454f-984e-5a8265afaab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>length</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues.00000.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.350088</td>\n",
       "      <td>0.088757</td>\n",
       "      <td>0.130228</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>1784.165850</td>\n",
       "      <td>129774.064525</td>\n",
       "      <td>2002.449060</td>\n",
       "      <td>85882.761315</td>\n",
       "      <td>...</td>\n",
       "      <td>52.420910</td>\n",
       "      <td>-1.690215</td>\n",
       "      <td>36.524071</td>\n",
       "      <td>-0.408979</td>\n",
       "      <td>41.597103</td>\n",
       "      <td>-2.303523</td>\n",
       "      <td>55.062923</td>\n",
       "      <td>1.221291</td>\n",
       "      <td>46.936035</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues.00001.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.340914</td>\n",
       "      <td>0.094980</td>\n",
       "      <td>0.095948</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>1530.176679</td>\n",
       "      <td>375850.073649</td>\n",
       "      <td>2039.036516</td>\n",
       "      <td>213843.755497</td>\n",
       "      <td>...</td>\n",
       "      <td>55.356403</td>\n",
       "      <td>-0.731125</td>\n",
       "      <td>60.314529</td>\n",
       "      <td>0.295073</td>\n",
       "      <td>48.120598</td>\n",
       "      <td>-0.283518</td>\n",
       "      <td>51.106190</td>\n",
       "      <td>0.531217</td>\n",
       "      <td>45.786282</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues.00002.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.363637</td>\n",
       "      <td>0.085275</td>\n",
       "      <td>0.175570</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>1552.811865</td>\n",
       "      <td>156467.643368</td>\n",
       "      <td>1747.702312</td>\n",
       "      <td>76254.192257</td>\n",
       "      <td>...</td>\n",
       "      <td>40.598766</td>\n",
       "      <td>-7.729093</td>\n",
       "      <td>47.639427</td>\n",
       "      <td>-1.816407</td>\n",
       "      <td>52.382141</td>\n",
       "      <td>-3.439720</td>\n",
       "      <td>46.639660</td>\n",
       "      <td>-2.231258</td>\n",
       "      <td>30.573025</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues.00003.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.404785</td>\n",
       "      <td>0.093999</td>\n",
       "      <td>0.141093</td>\n",
       "      <td>0.006346</td>\n",
       "      <td>1070.106615</td>\n",
       "      <td>184355.942417</td>\n",
       "      <td>1596.412872</td>\n",
       "      <td>166441.494769</td>\n",
       "      <td>...</td>\n",
       "      <td>44.427753</td>\n",
       "      <td>-3.319597</td>\n",
       "      <td>50.206673</td>\n",
       "      <td>0.636965</td>\n",
       "      <td>37.319130</td>\n",
       "      <td>-0.619121</td>\n",
       "      <td>37.259739</td>\n",
       "      <td>-3.407448</td>\n",
       "      <td>31.949339</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues.00004.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.308526</td>\n",
       "      <td>0.087841</td>\n",
       "      <td>0.091529</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>1835.004266</td>\n",
       "      <td>343399.939274</td>\n",
       "      <td>1748.172116</td>\n",
       "      <td>88445.209036</td>\n",
       "      <td>...</td>\n",
       "      <td>86.099236</td>\n",
       "      <td>-5.454034</td>\n",
       "      <td>75.269707</td>\n",
       "      <td>-0.916874</td>\n",
       "      <td>53.613918</td>\n",
       "      <td>-4.404827</td>\n",
       "      <td>62.910812</td>\n",
       "      <td>-11.703234</td>\n",
       "      <td>55.195160</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename  length  chroma_stft_mean  chroma_stft_var  rms_mean  \\\n",
       "0  blues.00000.wav  661794          0.350088         0.088757  0.130228   \n",
       "1  blues.00001.wav  661794          0.340914         0.094980  0.095948   \n",
       "2  blues.00002.wav  661794          0.363637         0.085275  0.175570   \n",
       "3  blues.00003.wav  661794          0.404785         0.093999  0.141093   \n",
       "4  blues.00004.wav  661794          0.308526         0.087841  0.091529   \n",
       "\n",
       "    rms_var  spectral_centroid_mean  spectral_centroid_var  \\\n",
       "0  0.002827             1784.165850          129774.064525   \n",
       "1  0.002373             1530.176679          375850.073649   \n",
       "2  0.002746             1552.811865          156467.643368   \n",
       "3  0.006346             1070.106615          184355.942417   \n",
       "4  0.002303             1835.004266          343399.939274   \n",
       "\n",
       "   spectral_bandwidth_mean  spectral_bandwidth_var  ...  mfcc16_var  \\\n",
       "0              2002.449060            85882.761315  ...   52.420910   \n",
       "1              2039.036516           213843.755497  ...   55.356403   \n",
       "2              1747.702312            76254.192257  ...   40.598766   \n",
       "3              1596.412872           166441.494769  ...   44.427753   \n",
       "4              1748.172116            88445.209036  ...   86.099236   \n",
       "\n",
       "   mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  \\\n",
       "0    -1.690215   36.524071    -0.408979   41.597103    -2.303523   55.062923   \n",
       "1    -0.731125   60.314529     0.295073   48.120598    -0.283518   51.106190   \n",
       "2    -7.729093   47.639427    -1.816407   52.382141    -3.439720   46.639660   \n",
       "3    -3.319597   50.206673     0.636965   37.319130    -0.619121   37.259739   \n",
       "4    -5.454034   75.269707    -0.916874   53.613918    -4.404827   62.910812   \n",
       "\n",
       "   mfcc20_mean  mfcc20_var  label  \n",
       "0     1.221291   46.936035  blues  \n",
       "1     0.531217   45.786282  blues  \n",
       "2    -2.231258   30.573025  blues  \n",
       "3    -3.407448   31.949339  blues  \n",
       "4   -11.703234   55.195160  blues  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata=pd.read_csv(\"Data/features_30_sec.csv\")\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4d3ec46-aa46-4e66-967a-b2e4840a273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(file):\n",
    "    audio, sample_rate=librosa.load(file_name, res_type=\"kaiser_fast\")\n",
    "    mfccs_features=librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_scaled_features=np.mean(mfccs_features.T,axis=0)\n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bfd1e34-1886-4458-85a8-aa3d78dabef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.drop(labels=552, axis=0 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "184e48d8-5ea0-4773-9201-ce178246cad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "553it [01:08,  8.94it/s]C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_31764\\4115935976.py:2: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, sample_rate=librosa.load(file_name, res_type=\"kaiser_fast\")\n",
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "555it [01:08, 11.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [01:57,  8.47it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "extracted_features=[]\n",
    "for index_num,row in tqdm(metadata.iterrows()):\n",
    "    try:\n",
    "        final_class_labels=row.label\n",
    "        file_name=os.path.join(os.path.abspath(audio_dataset_path), final_class_labels+'/',str(row[\"filename\"]))\n",
    "        data=features_extractor(file_name)\n",
    "        extracted_features.append([data,final_class_labels])\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a7c8f1b-0235-469c-954e-69b49bb71c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-113.59882, 121.57067, -19.162262, 42.363937,...</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-207.52383, 123.98514, 8.94702, 35.86715, 2.9...</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-90.757164, 140.44087, -29.084547, 31.686693,...</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-199.57513, 150.0861, 5.663404, 26.855278, 1....</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-160.35417, 126.20948, -35.581394, 22.139256,...</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature  class\n",
       "0  [-113.59882, 121.57067, -19.162262, 42.363937,...  blues\n",
       "1  [-207.52383, 123.98514, 8.94702, 35.86715, 2.9...  blues\n",
       "2  [-90.757164, 140.44087, -29.084547, 31.686693,...  blues\n",
       "3  [-199.57513, 150.0861, 5.663404, 26.855278, 1....  blues\n",
       "4  [-160.35417, 126.20948, -35.581394, 22.139256,...  blues"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
    "extracted_features_df.head()\n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a8766a5-4019-4162-a9c8-9d107ef39838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "blues        100\n",
       "classical    100\n",
       "country      100\n",
       "disco        100\n",
       "hiphop       100\n",
       "metal        100\n",
       "pop          100\n",
       "reggae       100\n",
       "rock         100\n",
       "jazz          98\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44b584c3-e5a9-4a92-8b04-5d07d8fd94d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(extracted_features_df['feature'].tolist())\n",
    "y=np.array(extracted_features_df['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cc41cc7-c2f9-4c84-89bb-da1c97612d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(998, 40)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f46ece8b-9bac-4b7c-8726-a29fa4f79b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y=to_categorical(labelencoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97be585e-d284-46a1-8f8b-f484bdf24306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(998, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15e5f6ae-83d7-4c7b-b6fd-d2dad62c8417",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02530fcb-62ba-41b1-abf2-f3bcc21269f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.04723763e+02,  8.77537231e+01, -3.32488594e+01, ...,\n",
       "        -2.38248777e+00, -1.36347115e+00, -7.22123563e-01],\n",
       "       [-2.59909851e+02,  1.23193169e+02, -6.39508581e+00, ...,\n",
       "        -6.73697710e+00, -3.90829563e+00,  3.18117642e+00],\n",
       "       [-1.15755066e+02,  6.70791245e+01,  1.88346887e+00, ...,\n",
       "        -3.43661404e+00, -1.73870683e+00, -4.68739159e-02],\n",
       "       ...,\n",
       "       [-1.25020428e+01,  9.13173676e+01, -2.30759563e+01, ...,\n",
       "        -4.04763985e+00, -1.77685583e+00, -1.75431299e+00],\n",
       "       [-2.37930965e+01,  8.29835587e+01,  2.32049274e+00, ...,\n",
       "         1.40550268e+00,  4.16220337e-01, -3.45979966e-02],\n",
       "       [-9.63197021e+01,  9.09497147e+01, -3.22195396e+01, ...,\n",
       "        -2.41483903e+00, -1.62698254e-01, -1.84749973e+00]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8681a54-ce41-4e0b-b5d3-b78386303973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(798, 40)\n",
      "(200, 40)\n",
      "(798, 10)\n",
      "(200, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "096a113c-5ddf-40a4-950b-230826d217b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e514a479-2e6d-41c4-b750-e9de5f3ceb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f275f8f8-351d-4ff9-b04b-ac907b95385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels=y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "077abbb4-ba70-4068-a1de-5b31e6b124fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e8132d0-9357-4b25-bbd2-0cc31a16272c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               4100      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 100)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               20200     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 200)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               20100     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45410 (177.38 KB)\n",
      "Trainable params: 45410 (177.38 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8186e796-66c5-4e69-8f54-f6e802e7ebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bde766ac-134b-450f-af4b-ba6ee3f494fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "19/25 [=====================>........] - ETA: 0s - loss: 26.7899 - accuracy: 0.0921\n",
      "Epoch 1: val_loss improved from inf to 4.08631, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 3s 35ms/step - loss: 23.6430 - accuracy: 0.1015 - val_loss: 4.0863 - val_accuracy: 0.0700\n",
      "Epoch 2/100\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 15.8797 - accuracy: 0.0625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/25 [====================>.........] - ETA: 0s - loss: 11.7192 - accuracy: 0.1128\n",
      "Epoch 2: val_loss improved from 4.08631 to 2.37381, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 10.8000 - accuracy: 0.1065 - val_loss: 2.3738 - val_accuracy: 0.1600\n",
      "Epoch 3/100\n",
      "20/25 [=======================>......] - ETA: 0s - loss: 7.2650 - accuracy: 0.1359\n",
      "Epoch 3: val_loss improved from 2.37381 to 2.23035, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 6.9274 - accuracy: 0.1328 - val_loss: 2.2304 - val_accuracy: 0.2450\n",
      "Epoch 4/100\n",
      "18/25 [====================>.........] - ETA: 0s - loss: 4.8819 - accuracy: 0.1406\n",
      "Epoch 4: val_loss improved from 2.23035 to 2.21887, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 4.8236 - accuracy: 0.1278 - val_loss: 2.2189 - val_accuracy: 0.2100\n",
      "Epoch 5/100\n",
      "20/25 [=======================>......] - ETA: 0s - loss: 3.9760 - accuracy: 0.1203\n",
      "Epoch 5: val_loss did not improve from 2.21887\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 3.9180 - accuracy: 0.1241 - val_loss: 2.2355 - val_accuracy: 0.2150\n",
      "Epoch 6/100\n",
      "19/25 [=====================>........] - ETA: 0s - loss: 3.4229 - accuracy: 0.1349\n",
      "Epoch 6: val_loss did not improve from 2.21887\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 3.3897 - accuracy: 0.1278 - val_loss: 2.2387 - val_accuracy: 0.2200\n",
      "Epoch 7/100\n",
      "18/25 [====================>.........] - ETA: 0s - loss: 3.0612 - accuracy: 0.1441\n",
      "Epoch 7: val_loss did not improve from 2.21887\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 3.0290 - accuracy: 0.1441 - val_loss: 2.2533 - val_accuracy: 0.1900\n",
      "Epoch 8/100\n",
      "19/25 [=====================>........] - ETA: 0s - loss: 2.9332 - accuracy: 0.0905\n",
      "Epoch 8: val_loss did not improve from 2.21887\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 2.8804 - accuracy: 0.1128 - val_loss: 2.2546 - val_accuracy: 0.2100\n",
      "Epoch 9/100\n",
      "20/25 [=======================>......] - ETA: 0s - loss: 2.6466 - accuracy: 0.1172\n",
      "Epoch 9: val_loss did not improve from 2.21887\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 2.6416 - accuracy: 0.1228 - val_loss: 2.2452 - val_accuracy: 0.1900\n",
      "Epoch 10/100\n",
      "19/25 [=====================>........] - ETA: 0s - loss: 2.6183 - accuracy: 0.1480\n",
      "Epoch 10: val_loss did not improve from 2.21887\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 2.5779 - accuracy: 0.1491 - val_loss: 2.2427 - val_accuracy: 0.2050\n",
      "Epoch 11/100\n",
      "21/25 [========================>.....] - ETA: 0s - loss: 2.4485 - accuracy: 0.1533\n",
      "Epoch 11: val_loss did not improve from 2.21887\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 2.4500 - accuracy: 0.1516 - val_loss: 2.2429 - val_accuracy: 0.1650\n",
      "Epoch 12/100\n",
      "20/25 [=======================>......] - ETA: 0s - loss: 2.4233 - accuracy: 0.1516\n",
      "Epoch 12: val_loss did not improve from 2.21887\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 2.4105 - accuracy: 0.1491 - val_loss: 2.2376 - val_accuracy: 0.1850\n",
      "Epoch 13/100\n",
      "19/25 [=====================>........] - ETA: 0s - loss: 2.3445 - accuracy: 0.1546\n",
      "Epoch 13: val_loss did not improve from 2.21887\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 2.3544 - accuracy: 0.1541 - val_loss: 2.2281 - val_accuracy: 0.1950\n",
      "Epoch 14/100\n",
      "20/25 [=======================>......] - ETA: 0s - loss: 2.3222 - accuracy: 0.1641\n",
      "Epoch 14: val_loss improved from 2.21887 to 2.21876, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 2.3204 - accuracy: 0.1692 - val_loss: 2.2188 - val_accuracy: 0.2100\n",
      "Epoch 15/100\n",
      "19/25 [=====================>........] - ETA: 0s - loss: 2.3613 - accuracy: 0.1414\n",
      "Epoch 15: val_loss improved from 2.21876 to 2.20436, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 2.3529 - accuracy: 0.1429 - val_loss: 2.2044 - val_accuracy: 0.2000\n",
      "Epoch 16/100\n",
      "19/25 [=====================>........] - ETA: 0s - loss: 2.3478 - accuracy: 0.1645\n",
      "Epoch 16: val_loss improved from 2.20436 to 2.18793, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 2.3362 - accuracy: 0.1667 - val_loss: 2.1879 - val_accuracy: 0.2200\n",
      "Epoch 17/100\n",
      "15/25 [=================>............] - ETA: 0s - loss: 2.3051 - accuracy: 0.1688\n",
      "Epoch 17: val_loss improved from 2.18793 to 2.17019, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 2.2527 - accuracy: 0.1855 - val_loss: 2.1702 - val_accuracy: 0.2400\n",
      "Epoch 18/100\n",
      "22/25 [=========================>....] - ETA: 0s - loss: 2.2731 - accuracy: 0.1776\n",
      "Epoch 18: val_loss improved from 2.17019 to 2.13311, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 2.2805 - accuracy: 0.1742 - val_loss: 2.1331 - val_accuracy: 0.2600\n",
      "Epoch 19/100\n",
      "17/25 [===================>..........] - ETA: 0s - loss: 2.2526 - accuracy: 0.1783\n",
      "Epoch 19: val_loss improved from 2.13311 to 2.12923, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 2.2502 - accuracy: 0.1892 - val_loss: 2.1292 - val_accuracy: 0.2900\n",
      "Epoch 20/100\n",
      "20/25 [=======================>......] - ETA: 0s - loss: 2.1760 - accuracy: 0.1922\n",
      "Epoch 20: val_loss improved from 2.12923 to 2.10951, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 2.1682 - accuracy: 0.1980 - val_loss: 2.1095 - val_accuracy: 0.2700\n",
      "Epoch 21/100\n",
      "16/25 [==================>...........] - ETA: 0s - loss: 2.2050 - accuracy: 0.1816\n",
      "Epoch 21: val_loss improved from 2.10951 to 2.08635, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 2.1970 - accuracy: 0.2018 - val_loss: 2.0864 - val_accuracy: 0.2600\n",
      "Epoch 22/100\n",
      "19/25 [=====================>........] - ETA: 0s - loss: 2.1520 - accuracy: 0.1974\n",
      "Epoch 22: val_loss improved from 2.08635 to 2.06952, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 2.1480 - accuracy: 0.2005 - val_loss: 2.0695 - val_accuracy: 0.2650\n",
      "Epoch 23/100\n",
      "19/25 [=====================>........] - ETA: 0s - loss: 2.1949 - accuracy: 0.2089\n",
      "Epoch 23: val_loss improved from 2.06952 to 2.04496, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 2.1869 - accuracy: 0.2080 - val_loss: 2.0450 - val_accuracy: 0.2700\n",
      "Epoch 24/100\n",
      "21/25 [========================>.....] - ETA: 0s - loss: 2.0981 - accuracy: 0.2381\n",
      "Epoch 24: val_loss improved from 2.04496 to 2.03081, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 2.1004 - accuracy: 0.2268 - val_loss: 2.0308 - val_accuracy: 0.3100\n",
      "Epoch 25/100\n",
      "18/25 [====================>.........] - ETA: 0s - loss: 2.1461 - accuracy: 0.2083\n",
      "Epoch 25: val_loss improved from 2.03081 to 1.99775, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 2.1539 - accuracy: 0.2080 - val_loss: 1.9977 - val_accuracy: 0.2950\n",
      "Epoch 26/100\n",
      "17/25 [===================>..........] - ETA: 0s - loss: 2.0959 - accuracy: 0.2592\n",
      "Epoch 26: val_loss improved from 1.99775 to 1.96586, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 2.0775 - accuracy: 0.2669 - val_loss: 1.9659 - val_accuracy: 0.3200\n",
      "Epoch 27/100\n",
      "18/25 [====================>.........] - ETA: 0s - loss: 2.0869 - accuracy: 0.2569\n",
      "Epoch 27: val_loss improved from 1.96586 to 1.94160, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 2.0816 - accuracy: 0.2506 - val_loss: 1.9416 - val_accuracy: 0.3200\n",
      "Epoch 28/100\n",
      "19/25 [=====================>........] - ETA: 0s - loss: 2.0929 - accuracy: 0.2467\n",
      "Epoch 28: val_loss improved from 1.94160 to 1.90721, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 2.0708 - accuracy: 0.2519 - val_loss: 1.9072 - val_accuracy: 0.3500\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - ETA: 0s - loss: 2.0341 - accuracy: 0.2619\n",
      "Epoch 29: val_loss did not improve from 1.90721\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 2.0341 - accuracy: 0.2619 - val_loss: 1.9104 - val_accuracy: 0.3550\n",
      "Epoch 30/100\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 2.0554 - accuracy: 0.2500\n",
      "Epoch 30: val_loss improved from 1.90721 to 1.89016, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 19ms/step - loss: 2.0399 - accuracy: 0.2544 - val_loss: 1.8902 - val_accuracy: 0.3600\n",
      "Epoch 31/100\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 1.9975 - accuracy: 0.2656\n",
      "Epoch 31: val_loss improved from 1.89016 to 1.86040, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 1.9982 - accuracy: 0.2694 - val_loss: 1.8604 - val_accuracy: 0.3700\n",
      "Epoch 32/100\n",
      "18/25 [====================>.........] - ETA: 0s - loss: 1.9897 - accuracy: 0.2830\n",
      "Epoch 32: val_loss did not improve from 1.86040\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 2.0248 - accuracy: 0.2732 - val_loss: 1.8640 - val_accuracy: 0.3700\n",
      "Epoch 33/100\n",
      "23/25 [==========================>...] - ETA: 0s - loss: 2.0201 - accuracy: 0.2745\n",
      "Epoch 33: val_loss improved from 1.86040 to 1.84740, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 2.0089 - accuracy: 0.2757 - val_loss: 1.8474 - val_accuracy: 0.3650\n",
      "Epoch 34/100\n",
      "19/25 [=====================>........] - ETA: 0s - loss: 1.9885 - accuracy: 0.2549\n",
      "Epoch 34: val_loss improved from 1.84740 to 1.84419, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 1.9784 - accuracy: 0.2556 - val_loss: 1.8442 - val_accuracy: 0.3800\n",
      "Epoch 35/100\n",
      "23/25 [==========================>...] - ETA: 0s - loss: 1.9329 - accuracy: 0.2799\n",
      "Epoch 35: val_loss improved from 1.84419 to 1.81592, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 1.9340 - accuracy: 0.2832 - val_loss: 1.8159 - val_accuracy: 0.3650\n",
      "Epoch 36/100\n",
      "20/25 [=======================>......] - ETA: 0s - loss: 1.9580 - accuracy: 0.2875\n",
      "Epoch 36: val_loss did not improve from 1.81592\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 1.9590 - accuracy: 0.2870 - val_loss: 1.8240 - val_accuracy: 0.3950\n",
      "Epoch 37/100\n",
      "20/25 [=======================>......] - ETA: 0s - loss: 1.8952 - accuracy: 0.3203\n",
      "Epoch 37: val_loss improved from 1.81592 to 1.80071, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 1.9050 - accuracy: 0.3108 - val_loss: 1.8007 - val_accuracy: 0.4100\n",
      "Epoch 38/100\n",
      "17/25 [===================>..........] - ETA: 0s - loss: 1.9083 - accuracy: 0.3125\n",
      "Epoch 38: val_loss improved from 1.80071 to 1.77678, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 1.9158 - accuracy: 0.3020 - val_loss: 1.7768 - val_accuracy: 0.4150\n",
      "Epoch 39/100\n",
      "17/25 [===================>..........] - ETA: 0s - loss: 1.9177 - accuracy: 0.3199\n",
      "Epoch 39: val_loss improved from 1.77678 to 1.76988, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 1.9227 - accuracy: 0.3233 - val_loss: 1.7699 - val_accuracy: 0.4100\n",
      "Epoch 40/100\n",
      "17/25 [===================>..........] - ETA: 0s - loss: 1.9242 - accuracy: 0.3199\n",
      "Epoch 40: val_loss improved from 1.76988 to 1.74689, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 1.9389 - accuracy: 0.3020 - val_loss: 1.7469 - val_accuracy: 0.4000\n",
      "Epoch 41/100\n",
      "18/25 [====================>.........] - ETA: 0s - loss: 1.8924 - accuracy: 0.3403\n",
      "Epoch 41: val_loss did not improve from 1.74689\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 1.9122 - accuracy: 0.3296 - val_loss: 1.7694 - val_accuracy: 0.4000\n",
      "Epoch 42/100\n",
      "19/25 [=====================>........] - ETA: 0s - loss: 1.8447 - accuracy: 0.3141\n",
      "Epoch 42: val_loss improved from 1.74689 to 1.72020, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 1.8408 - accuracy: 0.3195 - val_loss: 1.7202 - val_accuracy: 0.4200\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - ETA: 0s - loss: 1.9191 - accuracy: 0.3158\n",
      "Epoch 43: val_loss did not improve from 1.72020\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 1.9191 - accuracy: 0.3158 - val_loss: 1.7487 - val_accuracy: 0.4000\n",
      "Epoch 44/100\n",
      "18/25 [====================>.........] - ETA: 0s - loss: 1.8317 - accuracy: 0.3177\n",
      "Epoch 44: val_loss improved from 1.72020 to 1.71329, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 1.8205 - accuracy: 0.3258 - val_loss: 1.7133 - val_accuracy: 0.4250\n",
      "Epoch 45/100\n",
      "18/25 [====================>.........] - ETA: 0s - loss: 1.8021 - accuracy: 0.3524\n",
      "Epoch 45: val_loss improved from 1.71329 to 1.69253, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 1.8231 - accuracy: 0.3346 - val_loss: 1.6925 - val_accuracy: 0.3950\n",
      "Epoch 46/100\n",
      "20/25 [=======================>......] - ETA: 0s - loss: 1.8524 - accuracy: 0.3359\n",
      "Epoch 46: val_loss improved from 1.69253 to 1.67927, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 1.8570 - accuracy: 0.3346 - val_loss: 1.6793 - val_accuracy: 0.4250\n",
      "Epoch 47/100\n",
      "21/25 [========================>.....] - ETA: 0s - loss: 1.8073 - accuracy: 0.3601\n",
      "Epoch 47: val_loss did not improve from 1.67927\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 1.7865 - accuracy: 0.3609 - val_loss: 1.6838 - val_accuracy: 0.3950\n",
      "Epoch 48/100\n",
      "19/25 [=====================>........] - ETA: 0s - loss: 1.8012 - accuracy: 0.3454\n",
      "Epoch 48: val_loss improved from 1.67927 to 1.67907, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 1.8021 - accuracy: 0.3421 - val_loss: 1.6791 - val_accuracy: 0.4000\n",
      "Epoch 49/100\n",
      "18/25 [====================>.........] - ETA: 0s - loss: 1.7668 - accuracy: 0.3628\n",
      "Epoch 49: val_loss improved from 1.67907 to 1.63830, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 1.8009 - accuracy: 0.3446 - val_loss: 1.6383 - val_accuracy: 0.4050\n",
      "Epoch 50/100\n",
      "19/25 [=====================>........] - ETA: 0s - loss: 1.8301 - accuracy: 0.3618\n",
      "Epoch 50: val_loss did not improve from 1.63830\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 1.8144 - accuracy: 0.3672 - val_loss: 1.6614 - val_accuracy: 0.4350\n",
      "Epoch 51/100\n",
      "21/25 [========================>.....] - ETA: 0s - loss: 1.7709 - accuracy: 0.3467\n",
      "Epoch 51: val_loss did not improve from 1.63830\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 1.7825 - accuracy: 0.3509 - val_loss: 1.6390 - val_accuracy: 0.4300\n",
      "Epoch 52/100\n",
      "20/25 [=======================>......] - ETA: 0s - loss: 1.8507 - accuracy: 0.3422\n",
      "Epoch 52: val_loss improved from 1.63830 to 1.63710, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 1.8267 - accuracy: 0.3534 - val_loss: 1.6371 - val_accuracy: 0.4500\n",
      "Epoch 53/100\n",
      "20/25 [=======================>......] - ETA: 0s - loss: 1.7580 - accuracy: 0.3625\n",
      "Epoch 53: val_loss did not improve from 1.63710\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 1.7514 - accuracy: 0.3709 - val_loss: 1.6404 - val_accuracy: 0.4450\n",
      "Epoch 54/100\n",
      "22/25 [=========================>....] - ETA: 0s - loss: 1.7283 - accuracy: 0.3594\n",
      "Epoch 54: val_loss improved from 1.63710 to 1.61814, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 1.7378 - accuracy: 0.3584 - val_loss: 1.6181 - val_accuracy: 0.4500\n",
      "Epoch 55/100\n",
      "21/25 [========================>.....] - ETA: 0s - loss: 1.7587 - accuracy: 0.3646\n",
      "Epoch 55: val_loss improved from 1.61814 to 1.59036, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 1.7533 - accuracy: 0.3647 - val_loss: 1.5904 - val_accuracy: 0.4850\n",
      "Epoch 56/100\n",
      "21/25 [========================>.....] - ETA: 0s - loss: 1.7356 - accuracy: 0.3601\n",
      "Epoch 56: val_loss did not improve from 1.59036\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 1.7612 - accuracy: 0.3647 - val_loss: 1.6121 - val_accuracy: 0.4600\n",
      "Epoch 57/100\n",
      "21/25 [========================>.....] - ETA: 0s - loss: 1.7373 - accuracy: 0.3854\n",
      "Epoch 57: val_loss did not improve from 1.59036\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 1.7383 - accuracy: 0.3759 - val_loss: 1.5996 - val_accuracy: 0.4700\n",
      "Epoch 58/100\n",
      "21/25 [========================>.....] - ETA: 0s - loss: 1.7149 - accuracy: 0.3765\n",
      "Epoch 58: val_loss did not improve from 1.59036\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 1.7110 - accuracy: 0.3784 - val_loss: 1.5993 - val_accuracy: 0.4400\n",
      "Epoch 59/100\n",
      "23/25 [==========================>...] - ETA: 0s - loss: 1.6951 - accuracy: 0.3818\n",
      "Epoch 59: val_loss improved from 1.59036 to 1.56573, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 1.7023 - accuracy: 0.3835 - val_loss: 1.5657 - val_accuracy: 0.4600\n",
      "Epoch 60/100\n",
      "21/25 [========================>.....] - ETA: 0s - loss: 1.6432 - accuracy: 0.3586\n",
      "Epoch 60: val_loss did not improve from 1.56573\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.6650 - accuracy: 0.3534 - val_loss: 1.5868 - val_accuracy: 0.4550\n",
      "Epoch 61/100\n",
      "21/25 [========================>.....] - ETA: 0s - loss: 1.7008 - accuracy: 0.3869\n",
      "Epoch 61: val_loss did not improve from 1.56573\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 1.6968 - accuracy: 0.3759 - val_loss: 1.6049 - val_accuracy: 0.4400\n",
      "Epoch 62/100\n",
      "23/25 [==========================>...] - ETA: 0s - loss: 1.6926 - accuracy: 0.3655\n",
      "Epoch 62: val_loss did not improve from 1.56573\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.6998 - accuracy: 0.3659 - val_loss: 1.5664 - val_accuracy: 0.4450\n",
      "Epoch 63/100\n",
      "23/25 [==========================>...] - ETA: 0s - loss: 1.6626 - accuracy: 0.3886\n",
      "Epoch 63: val_loss did not improve from 1.56573\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 1.6535 - accuracy: 0.3910 - val_loss: 1.5949 - val_accuracy: 0.4300\n",
      "Epoch 64/100\n",
      "22/25 [=========================>....] - ETA: 0s - loss: 1.6813 - accuracy: 0.3935\n",
      "Epoch 64: val_loss improved from 1.56573 to 1.55657, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 1.6770 - accuracy: 0.3985 - val_loss: 1.5566 - val_accuracy: 0.4650\n",
      "Epoch 65/100\n",
      "20/25 [=======================>......] - ETA: 0s - loss: 1.6906 - accuracy: 0.4000\n",
      "Epoch 65: val_loss did not improve from 1.55657\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 1.6701 - accuracy: 0.3972 - val_loss: 1.5717 - val_accuracy: 0.4300\n",
      "Epoch 66/100\n",
      "21/25 [========================>.....] - ETA: 0s - loss: 1.6638 - accuracy: 0.3914\n",
      "Epoch 66: val_loss improved from 1.55657 to 1.55495, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 1.6430 - accuracy: 0.3947 - val_loss: 1.5549 - val_accuracy: 0.4250\n",
      "Epoch 67/100\n",
      "18/25 [====================>.........] - ETA: 0s - loss: 1.6635 - accuracy: 0.3976\n",
      "Epoch 67: val_loss did not improve from 1.55495\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 1.6642 - accuracy: 0.4110 - val_loss: 1.5706 - val_accuracy: 0.4500\n",
      "Epoch 68/100\n",
      "22/25 [=========================>....] - ETA: 0s - loss: 1.6601 - accuracy: 0.3849\n",
      "Epoch 68: val_loss improved from 1.55495 to 1.54277, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 1.6642 - accuracy: 0.3822 - val_loss: 1.5428 - val_accuracy: 0.4550\n",
      "Epoch 69/100\n",
      "20/25 [=======================>......] - ETA: 0s - loss: 1.5774 - accuracy: 0.4250\n",
      "Epoch 69: val_loss improved from 1.54277 to 1.53282, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 1.5946 - accuracy: 0.4148 - val_loss: 1.5328 - val_accuracy: 0.4700\n",
      "Epoch 70/100\n",
      "22/25 [=========================>....] - ETA: 0s - loss: 1.6707 - accuracy: 0.4119\n",
      "Epoch 70: val_loss improved from 1.53282 to 1.53159, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 1.6633 - accuracy: 0.4123 - val_loss: 1.5316 - val_accuracy: 0.4550\n",
      "Epoch 71/100\n",
      "22/25 [=========================>....] - ETA: 0s - loss: 1.6466 - accuracy: 0.4020\n",
      "Epoch 71: val_loss did not improve from 1.53159\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 1.6686 - accuracy: 0.3922 - val_loss: 1.5328 - val_accuracy: 0.4450\n",
      "Epoch 72/100\n",
      "22/25 [=========================>....] - ETA: 0s - loss: 1.5745 - accuracy: 0.4332\n",
      "Epoch 72: val_loss improved from 1.53159 to 1.50837, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 1.5666 - accuracy: 0.4398 - val_loss: 1.5084 - val_accuracy: 0.4800\n",
      "Epoch 73/100\n",
      "21/25 [========================>.....] - ETA: 0s - loss: 1.6141 - accuracy: 0.4226\n",
      "Epoch 73: val_loss did not improve from 1.50837\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 1.6259 - accuracy: 0.4160 - val_loss: 1.5183 - val_accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "22/25 [=========================>....] - ETA: 0s - loss: 1.5691 - accuracy: 0.4247\n",
      "Epoch 74: val_loss improved from 1.50837 to 1.49817, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 1.5763 - accuracy: 0.4198 - val_loss: 1.4982 - val_accuracy: 0.5250\n",
      "Epoch 75/100\n",
      "22/25 [=========================>....] - ETA: 0s - loss: 1.5876 - accuracy: 0.4077\n",
      "Epoch 75: val_loss did not improve from 1.49817\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.5885 - accuracy: 0.4073 - val_loss: 1.5181 - val_accuracy: 0.4750\n",
      "Epoch 76/100\n",
      "23/25 [==========================>...] - ETA: 0s - loss: 1.6088 - accuracy: 0.4090\n",
      "Epoch 76: val_loss improved from 1.49817 to 1.49354, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 1.5974 - accuracy: 0.4098 - val_loss: 1.4935 - val_accuracy: 0.5050\n",
      "Epoch 77/100\n",
      "20/25 [=======================>......] - ETA: 0s - loss: 1.5921 - accuracy: 0.4266\n",
      "Epoch 77: val_loss improved from 1.49354 to 1.46868, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 1.6102 - accuracy: 0.4223 - val_loss: 1.4687 - val_accuracy: 0.5250\n",
      "Epoch 78/100\n",
      "17/25 [===================>..........] - ETA: 0s - loss: 1.6460 - accuracy: 0.3934\n",
      "Epoch 78: val_loss did not improve from 1.46868\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 1.6399 - accuracy: 0.3972 - val_loss: 1.5049 - val_accuracy: 0.4650\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - ETA: 0s - loss: 1.5552 - accuracy: 0.4311\n",
      "Epoch 79: val_loss did not improve from 1.46868\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.5552 - accuracy: 0.4311 - val_loss: 1.4897 - val_accuracy: 0.5200\n",
      "Epoch 80/100\n",
      "13/25 [==============>...............] - ETA: 0s - loss: 1.5099 - accuracy: 0.4423\n",
      "Epoch 80: val_loss did not improve from 1.46868\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.5321 - accuracy: 0.4348 - val_loss: 1.4834 - val_accuracy: 0.4900\n",
      "Epoch 81/100\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 1.5167 - accuracy: 0.4557\n",
      "Epoch 81: val_loss did not improve from 1.46868\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.5343 - accuracy: 0.4486 - val_loss: 1.4710 - val_accuracy: 0.5100\n",
      "Epoch 82/100\n",
      "22/25 [=========================>....] - ETA: 0s - loss: 1.5110 - accuracy: 0.4403\n",
      "Epoch 82: val_loss did not improve from 1.46868\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 1.5095 - accuracy: 0.4386 - val_loss: 1.4777 - val_accuracy: 0.5000\n",
      "Epoch 83/100\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 1.5387 - accuracy: 0.4180\n",
      "Epoch 83: val_loss improved from 1.46868 to 1.44653, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 1.5371 - accuracy: 0.4198 - val_loss: 1.4465 - val_accuracy: 0.5200\n",
      "Epoch 84/100\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 1.5219 - accuracy: 0.4544\n",
      "Epoch 84: val_loss did not improve from 1.44653\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.5289 - accuracy: 0.4536 - val_loss: 1.4478 - val_accuracy: 0.5150\n",
      "Epoch 85/100\n",
      "13/25 [==============>...............] - ETA: 0s - loss: 1.4982 - accuracy: 0.4567\n",
      "Epoch 85: val_loss did not improve from 1.44653\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.4801 - accuracy: 0.4436 - val_loss: 1.4715 - val_accuracy: 0.4850\n",
      "Epoch 86/100\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 1.4993 - accuracy: 0.4583\n",
      "Epoch 86: val_loss improved from 1.44653 to 1.44366, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 1.5101 - accuracy: 0.4536 - val_loss: 1.4437 - val_accuracy: 0.5100\n",
      "Epoch 87/100\n",
      "21/25 [========================>.....] - ETA: 0s - loss: 1.4519 - accuracy: 0.4673\n",
      "Epoch 87: val_loss did not improve from 1.44366\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.4736 - accuracy: 0.4649 - val_loss: 1.4474 - val_accuracy: 0.5050\n",
      "Epoch 88/100\n",
      "19/25 [=====================>........] - ETA: 0s - loss: 1.4684 - accuracy: 0.4622\n",
      "Epoch 88: val_loss did not improve from 1.44366\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 1.4726 - accuracy: 0.4549 - val_loss: 1.4604 - val_accuracy: 0.4800\n",
      "Epoch 89/100\n",
      "23/25 [==========================>...] - ETA: 0s - loss: 1.5184 - accuracy: 0.4429\n",
      "Epoch 89: val_loss did not improve from 1.44366\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.5365 - accuracy: 0.4436 - val_loss: 1.4522 - val_accuracy: 0.5050\n",
      "Epoch 90/100\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 1.4504 - accuracy: 0.4779\n",
      "Epoch 90: val_loss did not improve from 1.44366\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.4495 - accuracy: 0.4774 - val_loss: 1.4599 - val_accuracy: 0.4850\n",
      "Epoch 91/100\n",
      "21/25 [========================>.....] - ETA: 0s - loss: 1.4803 - accuracy: 0.4539\n",
      "Epoch 91: val_loss improved from 1.44366 to 1.44229, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 1.4760 - accuracy: 0.4499 - val_loss: 1.4423 - val_accuracy: 0.5100\n",
      "Epoch 92/100\n",
      "20/25 [=======================>......] - ETA: 0s - loss: 1.4611 - accuracy: 0.4688\n",
      "Epoch 92: val_loss did not improve from 1.44229\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 1.4469 - accuracy: 0.4712 - val_loss: 1.4477 - val_accuracy: 0.4900\n",
      "Epoch 93/100\n",
      "23/25 [==========================>...] - ETA: 0s - loss: 1.4328 - accuracy: 0.4769\n",
      "Epoch 93: val_loss did not improve from 1.44229\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.4262 - accuracy: 0.4774 - val_loss: 1.4495 - val_accuracy: 0.5050\n",
      "Epoch 94/100\n",
      "22/25 [=========================>....] - ETA: 0s - loss: 1.4808 - accuracy: 0.4702\n",
      "Epoch 94: val_loss did not improve from 1.44229\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.4812 - accuracy: 0.4624 - val_loss: 1.4483 - val_accuracy: 0.4800\n",
      "Epoch 95/100\n",
      "22/25 [=========================>....] - ETA: 0s - loss: 1.4521 - accuracy: 0.4560\n",
      "Epoch 95: val_loss improved from 1.44229 to 1.43825, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 1.4680 - accuracy: 0.4549 - val_loss: 1.4383 - val_accuracy: 0.5000\n",
      "Epoch 96/100\n",
      "23/25 [==========================>...] - ETA: 0s - loss: 1.4323 - accuracy: 0.4851\n",
      "Epoch 96: val_loss improved from 1.43825 to 1.41912, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 1.4457 - accuracy: 0.4749 - val_loss: 1.4191 - val_accuracy: 0.4900\n",
      "Epoch 97/100\n",
      "20/25 [=======================>......] - ETA: 0s - loss: 1.3702 - accuracy: 0.4828\n",
      "Epoch 97: val_loss improved from 1.41912 to 1.40644, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 1.4059 - accuracy: 0.4712 - val_loss: 1.4064 - val_accuracy: 0.4850\n",
      "Epoch 98/100\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 1.4160 - accuracy: 0.4740\n",
      "Epoch 98: val_loss did not improve from 1.40644\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 1.4230 - accuracy: 0.4712 - val_loss: 1.4402 - val_accuracy: 0.4800\n",
      "Epoch 99/100\n",
      "22/25 [=========================>....] - ETA: 0s - loss: 1.3843 - accuracy: 0.4886\n",
      "Epoch 99: val_loss improved from 1.40644 to 1.38433, saving model to saved_models\\audio_classification.hdf5\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 1.4006 - accuracy: 0.4812 - val_loss: 1.3843 - val_accuracy: 0.5150\n",
      "Epoch 100/100\n",
      "21/25 [========================>.....] - ETA: 0s - loss: 1.4094 - accuracy: 0.4628\n",
      "Epoch 100: val_loss did not improve from 1.38433\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 1.4121 - accuracy: 0.4649 - val_loss: 1.4270 - val_accuracy: 0.5100\n",
      "Training time 0:00:30.434973\n"
     ]
    }
   ],
   "source": [
    "## Trianing my model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training time\", duration)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90ed32b3-2a5a-4e3c-8a18-5ed7ec68ff79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.4269911050796509, 0.5099999904632568]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffc09e32-aa51-43fc-af54-769c1ae38c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-75.35942   ,  83.35071   ,  10.695162  ,  14.4605    ,\n",
       "        14.239106  ,   7.397377  ,   5.2808986 ,  -0.3932319 ,\n",
       "         5.72108   ,   3.3658257 ,  -2.5226784 ,  -4.2161746 ,\n",
       "        -1.8445053 ,  -5.9071975 ,  -1.2714547 ,  -3.7691813 ,\n",
       "        -2.8537426 ,  -0.93226945,  -1.1161617 ,  -2.7156475 ,\n",
       "        -4.133138  ,  -0.56480694,   2.5117862 ,   1.8615217 ,\n",
       "         2.008656  ,   2.5816445 ,  -1.264946  ,  -4.4238324 ,\n",
       "        -2.666795  ,   0.88555604,   1.2533294 ,  -2.900544  ,\n",
       "        -4.5862637 ,  -2.5228503 ,  -0.8272398 ,   0.39746803,\n",
       "        -0.5501506 ,  -2.2381675 ,  -0.31077942,  -2.1934414 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8165c19b-e215-49f0-a498-8238809bf55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 7, 0, 2, 6, 7, 5, 9, 8, 2, 6, 4, 1, 1, 5, 7, 6, 5, 5, 5, 8, 5,\n",
       "       2, 0, 1, 7, 5, 0, 8, 6, 7, 4, 6, 8, 6, 6, 7, 5, 2, 7, 9, 9, 5, 3,\n",
       "       0, 8, 3, 3, 2, 6, 5, 8, 6, 5, 0, 2, 3, 2, 3, 6, 3, 5, 9, 3, 4, 2,\n",
       "       1, 4, 3, 1, 6, 3, 8, 9, 8, 9, 5, 4, 6, 3, 0, 6, 8, 8, 2, 5, 5, 5,\n",
       "       8, 9, 3, 0, 3, 9, 6, 7, 7, 5, 2, 5, 5, 8, 4, 8, 1, 4, 7, 8, 1, 6,\n",
       "       4, 4, 3, 8, 6, 2, 4, 6, 0, 5, 4, 5, 5, 0, 2, 7, 5, 8, 2, 3, 8, 9,\n",
       "       5, 4, 1, 9, 5, 4, 9, 2, 0, 9, 6, 0, 3, 0, 3, 3, 4, 8, 6, 5, 7, 8,\n",
       "       8, 9, 4, 4, 4, 8, 9, 8, 6, 4, 7, 1, 7, 5, 7, 5, 8, 6, 1, 7, 7, 1,\n",
       "       4, 7, 2, 7, 5, 9, 6, 5, 8, 8, 5, 6, 0, 7, 6, 6, 1, 2, 5, 2, 6, 3,\n",
       "       0, 5], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(X_test), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bffc285f-4c15-4d44-8dba-a85f00615d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-324.09128     133.56267     -25.030157     24.55361     -11.93992\n",
      "   17.658503     -5.5186734     1.7168901   -10.575926     -0.8605745\n",
      "   -7.80522       3.5297625     5.0546646     1.3707236     3.0050094\n",
      "   -3.1251519    -4.289579      0.59402454    2.877037      0.37455818\n",
      "   -1.2144454     0.7690288     2.2079859     1.0528629     5.3391447\n",
      "    2.526477      3.4166243    -1.2346429     6.6579533    11.365144\n",
      "   -0.9949533   -11.721296     -6.2246456     4.2277317     7.017335\n",
      "    5.0720463     2.523582     -5.4079676    -6.1680713     0.7645855 ]\n",
      "[[-324.09128     133.56267     -25.030157     24.55361     -11.93992\n",
      "    17.658503     -5.5186734     1.7168901   -10.575926     -0.8605745\n",
      "    -7.80522       3.5297625     5.0546646     1.3707236     3.0050094\n",
      "    -3.1251519    -4.289579      0.59402454    2.877037      0.37455818\n",
      "    -1.2144454     0.7690288     2.2079859     1.0528629     5.3391447\n",
      "     2.526477      3.4166243    -1.2346429     6.6579533    11.365144\n",
      "    -0.9949533   -11.721296     -6.2246456     4.2277317     7.017335\n",
      "     5.0720463     2.523582     -5.4079676    -6.1680713     0.7645855 ]]\n",
      "(1, 40)\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "[1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['classical'], dtype='<U9')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename=\"Data/genres_original/classical/classical.00001.wav\"\n",
    "audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
    "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "\n",
    "print(mfccs_scaled_features)\n",
    "mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
    "print(mfccs_scaled_features)\n",
    "print(mfccs_scaled_features.shape)\n",
    "predicted_label=np.argmax(model.predict(mfccs_scaled_features), axis=-1)\n",
    "print(predicted_label)\n",
    "prediction_class = labelencoder.inverse_transform(predicted_label) \n",
    "prediction_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87872117-27b7-4826-9d9c-f6317920d694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.0301540e+01  8.0847237e+01 -2.5676889e+01  3.8443054e+01\n",
      " -1.1072825e+01  2.4899410e+01 -7.3732128e+00  2.6759275e+01\n",
      " -5.3060298e+00  1.6782677e+01 -3.5075712e+00  8.4589281e+00\n",
      " -5.6017284e+00  1.2050404e+01 -1.8917377e+00  1.0464018e+01\n",
      "  6.4275295e-01  2.6245183e-01 -5.0987406e+00 -4.0196013e+00\n",
      " -2.4602270e+00 -2.3325288e+00 -6.7665046e-01 -1.6401160e+00\n",
      "  1.9417481e+00 -5.4288489e-01 -1.4439516e-01 -1.1494575e+00\n",
      "  3.1748803e+00 -1.1912193e-02 -1.1991701e+00 -4.0615096e+00\n",
      " -1.0737150e+00 -2.1080587e+00 -8.2540566e-01 -3.4200957e+00\n",
      " -1.9619328e+00 -1.4907260e+00 -1.3176049e+00 -3.2468905e+00]\n",
      "[[-4.0301540e+01  8.0847237e+01 -2.5676889e+01  3.8443054e+01\n",
      "  -1.1072825e+01  2.4899410e+01 -7.3732128e+00  2.6759275e+01\n",
      "  -5.3060298e+00  1.6782677e+01 -3.5075712e+00  8.4589281e+00\n",
      "  -5.6017284e+00  1.2050404e+01 -1.8917377e+00  1.0464018e+01\n",
      "   6.4275295e-01  2.6245183e-01 -5.0987406e+00 -4.0196013e+00\n",
      "  -2.4602270e+00 -2.3325288e+00 -6.7665046e-01 -1.6401160e+00\n",
      "   1.9417481e+00 -5.4288489e-01 -1.4439516e-01 -1.1494575e+00\n",
      "   3.1748803e+00 -1.1912193e-02 -1.1991701e+00 -4.0615096e+00\n",
      "  -1.0737150e+00 -2.1080587e+00 -8.2540566e-01 -3.4200957e+00\n",
      "  -1.9619328e+00 -1.4907260e+00 -1.3176049e+00 -3.2468905e+00]]\n",
      "(1, 40)\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "[4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['hiphop'], dtype='<U9')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename=\"Data/genres_original/hiphop/hiphop.00003.wav\"\n",
    "audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
    "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "\n",
    "print(mfccs_scaled_features)\n",
    "mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
    "print(mfccs_scaled_features)\n",
    "print(mfccs_scaled_features.shape)\n",
    "predicted_label=np.argmax(model.predict(mfccs_scaled_features),axis=-1)\n",
    "print(predicted_label)\n",
    "prediction_class = labelencoder.inverse_transform(predicted_label) \n",
    "prediction_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df2dbdd3-6611-4a0c-b309-a89e20c31e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model,open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c67bd73-5585-466f-a994-7b0f1fccc813",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
